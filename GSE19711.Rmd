---
title: 'GSE19711'
output: html_document
---

# Authors


- Rimvydas Noreika
- Tautminas Cibulskis
- Gabrielius Erignis
- Rolandas PorÄ—jus


# Analysis

```{r, echo=FALSE, include=FALSE}
library(GEOquery)
library(impute)
library(limma)
library(DT)
```

-Automatically download the data from GEO
```{r, include=FALSE, echo=FALSE}
gset = getGEO("GSE19711", destdir="./")
```

-Obtain the matrix of beta values where each row corresponds to probes and each column corresponds to samples
```{r}
gsetexpr = exprs(gset[[1]])
rownames(gsetexpr)[1:5]
colnames(gsetexpr)[1:5]
```

-How many samples and how many probes do you have in the data?
```{r}
sampleset = colnames(gsetexpr)
length(sampleset)

probeset = rownames(gsetexpr)
length(probeset)
```

-How are the beta values distributed?
```{r}
 hist(gsetexpr)
```

-Do your probes have names?
```{r}
probeset[1:5]
```

-Do you have annotation that tells the coordinate (in hg19) of each probe and its genomic features (such as related gene name)?
```{r}
annotation = getGEO("GPL8490", destdir = "./")
annotation = Table(annotation)
head(annotation)
```

-Do you know which samples correspond to healthy individuals, and which samples correspond to the sick ones?
```{r}
study = pData(phenoData(gset[[1]]))
group = study$`sample type:ch1`
group = sapply(strsplit(as.character(group), split=" "),'[[', 8)
group <- as.factor(group)
table(group)
```
For each probe compute a t-test to verify if the distributions of beta values within the probe significantly differ between the two groups. From the t-test, obtain the p value.
```{r}
pvalarray = array()
namearray = array()
for (i in 1:length(probeset)){
  case = gsetexpr[i, grep("Case", study$`sample type:ch1`)]
  control = gsetexpr[i, grep("Control", study$`sample type:ch1`)]
  tt = t.test(case, control)
  pvals <- tt$p.value
  pvalarray[i] = tt$p.value
  namearray[i] = probeset[i] 
}
```

Plot the distribution of p values. What is the expected distribution? How does it differ from what you get?
We get Anti-conservative p-values. All null p-values form a flat distribution. Peak is close to 0 - that is where the alternative hypotheses are. Not all p-values less than .05 are significant. High p-values indicate false negatives - hypotheses that are not detectable with our test. The left of the histogram shows significance. The right side shows how many p-values are null.

```{r}
hist(pvalarray, breaks = 100)
```
Performance-wise, how long will it take to compute the test for all probes?
Result is 51.228 seconds.

```{r}
system.time( for (i in 1:length(probeset)){
  case = gsetexpr[i, grep("Case", study$`sample type:ch1`)]
  control = gsetexpr[i, grep("Control", study$`sample type:ch1`)]
  tt = t.test(case, control)
  pvalarray[i] = tt$p.value
})
```
What is multiple hypothesis testing? Such testing means that we are trying to check validity of a number of hypotheses simultaneausly. However, as the number of hypotheses increases, o does the chance for observing at least one significant result by chance. In order to reduce the impact of this isssue, it is important to adjust for multiple hypothesis testing, so observing a significant result by chance is below our chosen significance level.


How should we adjust for multiple hypothesis testing in our case?

-What is multiple hypothesis testing?
Such testing means that we are trying to check validity of a number of hypotheses simultaneausly. However, as the number of hypotheses increases, o does the chance for observing at least one significant result by chance. In order to reduce the impact of this isssue, it is important to adjust for multiple hypothesis testing, so observing a significant result by chance is below our chosen significance level.

-How should we adjust for multiple hypothesis testing in our case?

```{r}
pvalarray.adjusted <- p.adjust(pvalarray, method="BH", n = length(pvalarray))
```
The p-values should be adjusted using "adjust" funtion. It is important to choose the right method to complete this action. In this case, "BH" method is the optimal one, since according to R documentation it controls the false discovery rate (proportion which is expected among the rejected hypotheses). This is exactly what we need in multiple hypothesis testing. It is also mentioned that these methods "are more powerful than others".


Did you find any probes that show statistically significant modification difference between healthy and sick individuals?
```{r}
pvalarray.significant <- pvalarray.adjusted[pvalarray.adjusted < 0.05]
namearray.significant <- namearray[pvalarray.adjusted < 0.05]
namearray.significant [1:20]
```
In this case we define smaller than 0.05 adjusted pvalue as "significant". The variables which are within this criteria are chosen and their names are printed.

Where are these probes? What genes are they related to?

-Did you find any probes that show statistically significant modification difference between healthy and sick individuals?
```{r}
pvalarray.significant <- pvalarray.adjusted[pvalarray.adjusted < 0.04]
namearray.significant <- namearray[pvalarray.adjusted < 0.04]
namearray.significant [1:20]
```
In this case we define smaller than 0.04 adjusted pvalue as "significant". The variables which are within this criteria are chosen and their names are printed. 

-Where are these probes? What genes are they related to?

```{r}
genes <- annotation$Gene_ID[match(namearray.significant, annotation$ID)]
location <- annotation$CPG_ISLAND_LOCATIONS[match(namearray.significant, annotation$ID)]
genes [1:20]
location [1:20]
```
We should find genes and then chromosomes (where probes are located). We do so by matching the names of adjusted pvalues and annotation IDs.


NEXT STEPS:

Normalization

```{r}
normmat = limma::normalizeBetweenArrays(gsetexpr)
```

Creating dataset with SampleID's, DNAmAge, predicted gender and adding case and control groups

```{r}
data711 = read.csv('GSE19711.csv')
data711$Group = group
head(data711)
```

visualizing the spread of case and control groups and applying t-tests to our dataset

```{r}
with(data711, boxplot(DNAmAge ~ Group))
with(data711, t.test(DNAmAge ~ Group))
```

adding blood cell composition to dataset 

```{r}
cellCounts = read.csv('GSE19711_cellCounts.csv')
stopifnot(all(data711$SampleID == cellCounts$X))
data711$Bcell <- cellCounts$Bcell
data711$CD4T <- cellCounts$CD4T
data711$CD8T <- cellCounts$CD8T
data711$Gran <- cellCounts$Gran
data711$Mono <- cellCounts$Mono
data711$NK <- cellCounts$NK
```

Imputation using k-nearest neighbors algorithm. We need to replace missing data with substituted values.
In this algorithm missing data is imputed based on the mean of non-missing values of the neighbors.

```{r, results="hide"}
imputed <- impute.knn(normmat)
```

PCA before removal of outliers and sex chromosome probes

```{r}
pca = prcomp(t(imputed$data), scale=FALSE)
pairs(pca$x[,1:4], col=as.factor(data711$predictedGender))
```

Performing t-tests, seeing which principal components are affected by control group, DNAmAge and blood cell composition data

```{r}
model <- model.matrix(~ Group + DNAmAge + Bcell + CD4T + CD8T + Gran + Mono + NK, data = data711)
fit <- lmFit(t(pca$x[, 1:10]), model)
fit <- eBayes(fit)
toptable(fit)
decideTests(fit)
```

Selecting sex chromosome probes

```{r}
sexProbes <- which(annotation$Chr %in% c("X", "Y"))
```

Impute without sex chromosome probes

```{r, results="hide"}
imputed <- impute.knn(normmat[-sexProbes,])
```

PCA after removal of sex chromosome probes

```{r}
pca <- prcomp(t(imputed$data), scale=FALSE)
pairs(pca$x[,1:4], col=as.factor(data711$predictedGender))
```

Some samples could be outliers messing up our results. How to detect outliers?
We select outliers who are further than 3 standart deviations from the mean.

```{r}
out1 <- abs(pca$x[,1] - mean(pca$x[,1])) > 3*sd(pca$x[,1])
out2 <- abs(pca$x[,2] - mean(pca$x[,2])) > 3*sd(pca$x[,2])
outs <- which(out1 | out2)
```

Removal of outliers and sex chromosome probes and Normalization

```{r}
normmat = limma::normalizeBetweenArrays(gsetexpr[-sexProbes, -outs])
```

Imputation after removal of outliers and sex chromosome probes

```{r, results="hide"}
imputed <- impute.knn(normmat)
```

PCA after removal of outliers and sex chromosome probes

```{r}
pca = prcomp(t(imputed$data), scale=FALSE)
pairs(pca$x[,1:4], col=as.factor(data711$predictedGender[-outs]))
```

Performing t-tests after removal of outliers, seeing which principal components are affected by control group, DNAmAge and blood cell composition data

```{r}
model <- model.matrix(~ Group + DNAmAge + Bcell + CD4T + CD8T + Gran + Mono + NK, data = data711[-outs,])
fit <- lmFit(t(pca$x[, 1:10]), model)
fit <- eBayes(fit)
toptable(fit)
decideTests(fit)
```

Test each probe for differences

```{r}
computeFit <- function(permute = FALSE) {
	if (!permute) {
		model <- model.matrix(~ Group + DNAmAge, data=data711[-outs,])
	} else {
		model <- model.matrix(~ sample(Group) + DNAmAge, data=data711[-outs,])		
	}
	fit <- lmFit(imputed$data, model)
	fit <- eBayes(fit)
	fit <- topTable(fit, coef=2, number=nrow(imputed$data), sort.by="none")
	return(fit)	
}

fit <- computeFit()
```

Histogram of p-values

```{r}

hist(fit$P.Value, breaks=100)
```

Permutations!!

```{r}
set.seed(123)
n = 100
observed = mean(fit$P.Value < 0.05)
#expected = numeric(n)
#for(iteration in 1:n){
#  permutedFit <- computeFit(permute = TRUE)
#  expected[i] <- mean(permutedFit$P.Value < 0.05)
#}
```
Permutations!! (faster)

```{r, echo=FALSE, include=FALSE}
require(doSNOW)
require(foreach)

# Sita funkcija paleidzia atskirus R procesus, nukopijuoja i 
# juos duomenis ir paleidzia skaiciuoti paraleliai. 
CLUSTER <- NULL
withCluster <- function(action, outfile="", nNodes=0) {
	require(doSNOW)
	if (nNodes == 0) {
	    nodefile <- Sys.getenv("PBS_NODEFILE")
	    hosts <- readLines(nodefile)
	} else {
	    hosts <- rep("localhost", nNodes)
	}
    message(sprintf("Starting cluster on %s", paste(hosts, collapse=", ")))
    CLUSTER <<- makeCluster(hosts, type="SOCK", outfile=outfile)		
    registerDoSNOW(CLUSTER)
    clusterSetupRNG(CLUSTER)
    tryCatch(action, finally={
        message("Stopping cluster")
        registerDoSEQ()
        stopCluster(CLUSTER)
        CLUSTER <<- NULL
    })
}

expected <- withCluster(
	foreach(i = 1:n, 
		.combine=c) %dopar% {
		
		require(limma)
		permutedFit <- computeFit(permute = TRUE)
		mean(permutedFit$P.Value < 0.05)
	}, 
	nNodes=6
)
```

How likely is it to see so many significant probes in randomly shuffled data.

```{r}
p <- mean(expected > observed)
hist(expected, breaks=20, main=paste("The test p =", p))
abline(v=observed, col="red")
```

Result: changed probes

```{r, echo=FALSE}
interestingColumns <- c("ID", "Chr", "MapInfo", "Symbol", "Distance_to_TSS", "CPG_ISLAND")
res <- cbind(fit, annotation[-sexProbes, interestingColumns])
i <- which(res$adj.P.Val < 0.05)
res <- res[i,]
o <- order(res$P.Value)
res <- res[o,]
datatable(res, class = 'cell-border stripe')
```
