---
title: 'GSE19711'
output: html_document
---

# Authors


- Rimvydas Noreika
- Tautminas Cibulskis
- Gabrielius Erignis
- Rolandas Porėjus


# Analysis

```{r, echo=FALSE, include=FALSE}
library(GEOquery)
library(impute)
library(limma)
library(DT)
```

-Automatically download the data from GEO
```{r, echo=FALSE}
gset = getGEO("GSE19711", destdir="./")
```

-Obtain the matrix of beta values where each row corresponds to probes and each column corresponds to samples
```{r}
gsetexpr = exprs(gset[[1]])
rownames(gsetexpr)[1:5]
colnames(gsetexpr)[1:5]
```

-How many samples and how many probes do you have in the data?
```{r}
sampleset = colnames(gsetexpr)
length(sampleset)

probeset = rownames(gsetexpr)
length(probeset)
```

-How are the beta values distributed?
```{r}
 hist(gsetexpr)
```

-Do your probes have names?
```{r}
probeset[1:5]
```

-Do you have annotation that tells the coordinate (in hg19) of each probe and its genomic features (such as related gene name)?
```{r}
annotation = getGEO("GPL8490", destdir = "./")
annotation = Table(annotation)
head(annotation)
```

-Do you know which samples correspond to healthy individuals, and which samples correspond to the sick ones?
```{r}
study = pData(phenoData(gset[[1]]))
group = study$`sample type:ch1`
group = sapply(strsplit(as.character(group), split=" "),'[[', 8)
group <- as.factor(group)
table(group)
```
For each probe compute a t-test to verify if the distributions of beta values within the probe significantly differ between the two groups. From the t-test, obtain the p value.
```{r}
pvalarray = array()
namearray = array()
for (i in 1:length(probeset)){
  case = gsetexpr[i, grep("Case", study$`sample type:ch1`)]
  control = gsetexpr[i, grep("Control", study$`sample type:ch1`)]
  tt = t.test(case, control)
  pvals <- tt$p.value
  pvalarray[i] = tt$p.value
  namearray[i] = probeset[i] 
}
```

Plot the distribution of p values. What is the expected distribution? How does it differ from what you get?
We get Anti-conservative p-values. All null p-values form a flat distribution. Peak is close to 0 - that is where the alternative hypotheses are. Not all p-values less than .05 are significant. High p-values indicate false negatives - hypotheses that are not detectable with our test. The left of the histogram shows significance. The right side shows how many p-values are null.

```{r}
hist(pvalarray, breaks = 100)
```
Performance-wise, how long will it take to compute the test for all probes?
Result is 51.228 seconds.

```{r}
system.time( for (i in 1:length(probeset)){
  case = gsetexpr[i, grep("Case", study$`sample type:ch1`)]
  control = gsetexpr[i, grep("Control", study$`sample type:ch1`)]
  tt = t.test(case, control)
  pvalarray[i] = tt$p.value
})
```
What is multiple hypothesis testing? Such testing means that we are trying to check validity of a number of hypotheses simultaneausly. However, as the number of hypotheses increases, o does the chance for observing at least one significant result by chance. In order to reduce the impact of this isssue, it is important to adjust for multiple hypothesis testing, so observing a significant result by chance is below our chosen significance level.


How should we adjust for multiple hypothesis testing in our case?

-What is multiple hypothesis testing?
Such testing means that we are trying to check validity of a number of hypotheses simultaneausly. However, as the number of hypotheses increases, o does the chance for observing at least one significant result by chance. In order to reduce the impact of this isssue, it is important to adjust for multiple hypothesis testing, so observing a significant result by chance is below our chosen significance level.

-How should we adjust for multiple hypothesis testing in our case?

```{r}
pvalarray.adjusted <- p.adjust(pvalarray, method="BH", n = length(pvalarray))
```
The p-values should be adjusted using "adjust" funtion. It is important to choose the right method to complete this action. In this case, "BH" method is the optimal one, since according to R documentation it controls the false discovery rate (proportion which is expected among the rejected hypotheses). This is exactly what we need in multiple hypothesis testing. It is also mentioned that these methods "are more powerful than others".


Did you find any probes that show statistically significant modification difference between healthy and sick individuals?
```{r}
pvalarray.significant <- pvalarray.adjusted[pvalarray.adjusted < 0.05]
namearray.significant <- namearray[pvalarray.adjusted < 0.05]
namearray.significant [1:20]
```
In this case we define smaller than 0.05 adjusted pvalue as "significant". The variables which are within this criteria are chosen and their names are printed.

Where are these probes? What genes are they related to?

-Did you find any probes that show statistically significant modification difference between healthy and sick individuals?
```{r}
pvalarray.significant <- pvalarray.adjusted[pvalarray.adjusted < 0.04]
namearray.significant <- namearray[pvalarray.adjusted < 0.04]
namearray.significant [1:20]
```
In this case we define smaller than 0.04 adjusted pvalue as "significant". The variables which are within this criteria are chosen and their names are printed. 

-Where are these probes? What genes are they related to?

```{r}
genes <- annotation$Gene_ID[match(namearray.significant, annotation$ID)]
location <- annotation$CPG_ISLAND_LOCATIONS[match(namearray.significant, annotation$ID)]
genes [1:20]
location [1:20]
```
We should find genes and then chromosomes (where probes are located). We do so by matching the names of adjusted pvalues and annotation IDs.


Normalizavimas, kvantiliu normalizacija

```{r}
normmat = limma::normalizeBetweenArrays(gsetexpr)
```

PCA before removal of outliers and sex chromosome probes

```{r}
data711 = read.csv('GSE19711.csv')
data711$Group = group
head(data711)
with(data711, boxplot(DNAmAge ~ Group))
with(data711, t.test(DNAmAge ~ Group))

imputed <- impute.knn(normmat)
pca = prcomp(t(imputed$data), scale=FALSE)
pairs(pca$x[,1:4], col=as.factor(data711$predictedGender))


model <- model.matrix(~ Group + DNAmAge, data = data711)
fit <- lmFit(t(pca$x[, 1:10]), model)
fit <- eBayes(fit)
topTable(fit)
decideTests(fit)


```

Reikia atmesti lytiniu chromosomu probus

```{r}
sexProbes <- which(annotation$Chr %in% c("X", "Y"))
imputed <- impute.knn(normmat[-sexProbes,])
pca <- prcomp(t(imputed$data), scale=FALSE)
pairs(pca$x[,1:4], col=as.factor(data711$predictedGender))
```

Some samples could be outliers messing up our results. How to detect outliers?

```{r}
out1 <- abs(pca$x[,1] - mean(pca$x[,1])) > 3*sd(pca$x[,1])
out2 <- abs(pca$x[,2] - mean(pca$x[,2])) > 3*sd(pca$x[,2])
outs <- which(out1 | out2)
```

PCA after removal of outliers and sex chromosome probes

```{r}
normmat = limma::normalizeBetweenArrays(gsetexpr[-sexProbes, -outs])

imputed <- impute.knn(normmat)
pca = prcomp(t(imputed$data), scale=FALSE)
pairs(pca$x[,1:4], col=as.factor(data711$predictedGender[-outs]))

model <- model.matrix(~ Group + DNAmAge, data = data711[-outs,])
fit <- lmFit(t(pca$x[, 1:10]), model)
fit <- eBayes(fit)
topTable(fit)
decideTests(fit)

plot(pca$x[,1], pca$x[,3], col=as.factor(data711$Group[-outs]))
boxplot(pca$x[,1] ~ as.factor(data711$Group[-outs]))

model <- glm(as.factor(Group) ~ pca$x[,1] + pca$x[,3] + DNAmAge, data=data711[-outs,], family="binomial")
model0 <- glm(as.factor(Group) ~ DNAmAge, data=data711[-outs,], family="binomial")
anova(model0, model, test="Chisq")

computeFit <- function(permute = FALSE) {
	if (!permute) {
		model <- model.matrix(~ Group + DNAmAge, data=data711[-outs,])
	} else {
		model <- model.matrix(~ sample(Group) + DNAmAge, data=data711[-outs,])		
	}
	fit <- lmFit(imputed$data, model)
	fit <- eBayes(fit)
	fit <- topTable(fit, coef=2, number=nrow(imputed$data), sort.by="none")
	return(fit)	
}

fit <- computeFit()
#Histogram of p-values
hist(fit$P.Value, breaks=100)
#Number of significant probes
cat("Fraction with p < 0.05 ", mean(fit$P.Value < 0.05), "\n")
cat("Total FDR q < 0.05 ", sum(p.adjust(fit$P.Value, "fdr") < 0.05), "\n")
```

Permutacijos!!

```{r}
set.seed(123)
n = 100
observed = mean(fit$P.Value < 0.05)
#expected = numeric(n)
#for(iteration in 1:n){
#  permutedFit <- computeFit(permute = TRUE)
#  expected[i] <- mean(permutedFit$P.Value < 0.05)
#}
```
Permutacijos!! (Greičiau)

```{r, echo=FALSE}
require(doSNOW)
require(foreach)

# Sita funkcija paleidzia atskirus R procesus, nukopijuoja i 
# juos duomenis ir paleidzia skaiciuoti paraleliai. 
CLUSTER <- NULL
withCluster <- function(action, outfile="", nNodes=0) {
	require(doSNOW)
	if (nNodes == 0) {
	    nodefile <- Sys.getenv("PBS_NODEFILE")
	    hosts <- readLines(nodefile)
	} else {
	    hosts <- rep("localhost", nNodes)
	}
    message(sprintf("Starting cluster on %s", paste(hosts, collapse=", ")))
    CLUSTER <<- makeCluster(hosts, type="SOCK", outfile=outfile)		
    registerDoSNOW(CLUSTER)
    clusterSetupRNG(CLUSTER)
    tryCatch(action, finally={
        message("Stopping cluster")
        registerDoSEQ()
        stopCluster(CLUSTER)
        CLUSTER <<- NULL
    })
}

expected <- withCluster(
	foreach(i = 1:n, 
		.combine=c) %dopar% {
		
		require(limma)
		permutedFit <- computeFit(permute = TRUE)
		mean(permutedFit$P.Value < 0.05)
	}, 
	nNodes=6
)
```

How likely is it to see so many significant probes in randomly shuffled data.

```{r}
p <- mean(expected > observed)
hist(expected, breaks=20, main=paste("The test p =", p))
abline(v=observed, col="red")
```

Rezultatas: pakite probai!!!
```{r, echo=FALSE}
interestingColumns <- c("ID", "Chr", "MapInfo", "Symbol", "Distance_to_TSS", "CPG_ISLAND")
res <- cbind(fit, annotation[-sexProbes, interestingColumns])
i <- which(res$adj.P.Val < 0.05)
res <- res[i,]
o <- order(res$P.Value)
res <- res[o,]
datatable(res, class = 'cell-border stripe')
```
